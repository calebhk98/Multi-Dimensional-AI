# Stage 5: Backpropagation (End-to-End Training) Config

defaults:
    device: "cuda"
    save_dir: "checkpoints/stage5"

model:
    encoders:
        internal_voice:
            vocab_size: 50257
            embedding_dim: 768
        external_voice:
            vocab_size: 50257
            embedding_dim: 768
        audio:
            # Audio encoder params
            sample_rate: 16000
        vision:
            image_size: 224
            patch_size: 16
        proprioception:
            num_joints: 24
            temporal_window: 10
        touch:
            max_contacts: 5

    transformer:
        num_layers: 12
        hidden_dim: 1536
        num_attention_heads: 16
        ffn_dim: 6144
        dropout: 0.1

    fusion:
        strategy: "concatenate" # or "cross_attention"
        modality_embeddings: true

    decoders:
        internal_text:
            vocab_size: 50257
        external_text:
            vocab_size: 50257
        audio:
            codebook_size: 1024
        animation:
            num_joints: 24

multimodal:
    dataset:
        vocab_size: 50257
        max_seq_length: 64

training:
    batch_size: 4
    max_steps: 1000
    log_interval: 10
    save_interval: 200

    optimizer:
        lr: 1e-4
        betas: [0.9, 0.95]
        weight_decay: 0.1

    # Loss weights for valid outputs
    loss_weights:
        internal_text: 1.0
        external_text: 1.0
        audio: 1.0
        animation: 1.0
